{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Problem Statement: **Optimization of AtliQ's Fashion Image Classifier**\n",
        "\n",
        "### AtliQ Retail wants to develop a neural network model to classify fashion items from the **FashionMNIST** dataset. Your task is to optimize the model's performance by experimenting with different optimization algorithms."
      ],
      "metadata": {
        "id": "GykHdpSv3l9o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports and CUDA"
      ],
      "metadata": {
        "id": "zhs9sH0V3r5G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGigf9_3fKLO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "\n",
        "# Check if CUDA (GPU) is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "EVDqU3dSmveI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step1**: Load and Sample the Dataset"
      ],
      "metadata": {
        "id": "urfF_b6bfyoY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = # Code Here\n",
        "\n",
        "train_subset_size =\n",
        "test_subset_size ="
      ],
      "metadata": {
        "id": "Nd1I6Ucsf2K2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "AXumd8Yzmw62"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step2**: Create Dataloaders\n",
        "\n",
        "* batch size = 32"
      ],
      "metadata": {
        "id": "PztKX1NGgOKu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_subset, _ = random_split(dataset, [train_subset_size, len(dataset) - train_subset_size])\n",
        "test_subset, _ = # Code Here"
      ],
      "metadata": {
        "id": "TxpFCADKgNy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size =\n",
        "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = # Code Here"
      ],
      "metadata": {
        "id": "HGS5OljwgWvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check a sample image in FashionMNIST Dataset\n",
        "\n",
        "for images, labels in train_loader:\n",
        "    print(images.shape, labels.shape)\n",
        "    break\n",
        "\n",
        "plt.figure(figsize=(2,2))\n",
        "plt.imshow(images[7].todevice().squeeze(), cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rS8Iwws14j_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "nhPDzGIUmyK0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step3**: Define the Neural Network\n",
        "\n",
        "* Create a fully connected feed-forward neural network (no CNN).\n",
        "\n",
        "Structure:\n",
        "* Input layer: 784 neurons (28x28 image flattened).\n",
        "* 1st hidden layer: 128 neurons with ReLU activation.\n",
        "* 2nd hidden layer: 64 neurons with ReLU activation.\n",
        "* Output layer: 10 neurons (one for each class) with Softmax activation.\n",
        "* Use `CrossEntropyLoss `as Loss Function\n",
        "\n",
        "Use `nn.Sequential`"
      ],
      "metadata": {
        "id": "rt4PsGkegkrE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FashionNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FashionNN, self).__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            # Flatten the input tensor\n",
        "\n",
        "            # Input layer (784)\n",
        "\n",
        "            # Activation\n",
        "\n",
        "            # Hidden layer 1\n",
        "\n",
        "            # Activation\n",
        "\n",
        "            # Output layer (10 classes)\n",
        "\n",
        "            # Softmax for probabilities\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "model = # Code Here\n",
        "print(model)\n",
        "\n",
        "loss_fn = # Code Here"
      ],
      "metadata": {
        "id": "XkUswxj6gp25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "UKxmiR8mmzs6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step4**: Train and Evaluate with SGD\n",
        "\n",
        "* set number of epochs to 10\n",
        "* `lr` = 0.01\n",
        "* momentum = 0.0\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hq7Z2QCThL1M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set number of epochs\n",
        "num_epochs = 10\n",
        "\n",
        "# Initialize the optimizer\n",
        "\n",
        "# Store loss for each epoch\n",
        "epoch_losses = []\n",
        "\n",
        "# Train the model for num_epochs\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        optimizer_sgd.zero_grad()\n",
        "        outputs = # Code Here\n",
        "        loss = # Code Here\n",
        "        loss.backward()\n",
        "        optimizer_sgd.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Calculate average loss for the epoch\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    epoch_losses.append(epoch_loss)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "# Step 2: Calculate accuracy after all epochs\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"Accuracy with SGD optimizer: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "id": "RqJ5sbywlFg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot predictions vs true labels for the first 9 images\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    # Grab a batch of test data\n",
        "    images, labels = next(iter(test_loader))\n",
        "    outputs = model(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    # Plot the first 9 images with predictions and true labels\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    for i in range(25):\n",
        "        plt.subplot(5, 5, i+1)\n",
        "        plt.imshow(images[i].squeeze(), cmap='gray')\n",
        "        plt.title(f\"Pred: {predicted[i].item()}, True: {labels[i].item()}\")\n",
        "        plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "3Fo6cJja1Vty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "T5pX9eYJm02m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step5**: Train with SGD and Momentum\n",
        "\n",
        "* set number of epochs to 10\n",
        "* `lr` = 0.01\n",
        "* momentum = 0.9"
      ],
      "metadata": {
        "id": "nyaYf8Skl0K6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set number of epochs\n",
        "num_epochs = 10\n",
        "\n",
        "# Initialize the optimizer\n",
        "optimizer_momentum = # Code Here\n",
        "\n",
        "# Store loss for each epoch\n",
        "epoch_losses = []\n",
        "\n",
        "# Train the model for num_epochs\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        optimizer_momentum.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer_momentum.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Calculate average loss for the epoch\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    epoch_losses.append(epoch_loss)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "# Step 2: Calculate accuracy after all epochs\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"Accuracy with Momentum optimizer: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "id": "6DSn8oWXl6Hq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot predictions vs true labels for the first 9 images\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    # Grab a batch of test data\n",
        "    images, labels = next(iter(test_loader))\n",
        "    outputs = model(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    # Plot the first 9 images with predictions and true labels\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    for i in range(25):\n",
        "        plt.subplot(5, 5, i+1)\n",
        "        plt.imshow(images[i].squeeze(), cmap='gray')\n",
        "        plt.title(f\"Pred: {predicted[i].item()}, True: {labels[i].item()}\")\n",
        "        plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "pzljMkd61rNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "c-ZZiUP_m17k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step6**: Training with RMS Prop\n",
        "\n",
        "* set number of epochs to 10\n",
        "* `lr` = 0.001\n",
        "* alpha = 0.9"
      ],
      "metadata": {
        "id": "sVJB5g7KmDkn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set number of epochs\n",
        "num_epochs = 10\n",
        "\n",
        "# Initialize the optimizer\n",
        "optimizer_rms = # Code Here\n",
        "\n",
        "# Store loss for each epoch\n",
        "epoch_losses = []\n",
        "\n",
        "# Train the model for num_epochs\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        optimizer_rms.zero_grad()\n",
        "        outputs = # Code Here\n",
        "        loss = # Code Here\n",
        "        loss.backward()\n",
        "        optimizer_rms.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Calculate average loss for the epoch\n",
        "    epoch_loss = # Code Here\n",
        "    epoch_losses.append(epoch_loss)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "# Step 2: Calculate accuracy after all epochs\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total = # Code Here\n",
        "        correct = # Code Here\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"Accuracy with RMS optimizer: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "id": "qm6OiK-5mKbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ATukrSFN2-V-"
      }
    }
  ]
}