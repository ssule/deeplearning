{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Problem Statement: **Hyperparameter Tuning for AtliQ’s Fashion Item Classifier**\n",
        "\n",
        "### AtliQ Fashion wants to develop a neural network to classify fashion items using the FashionMNIST dataset. Your task is to optimize the neural network's performance by fine-tuning its hyperparameters. We will be using **FashionMNIST** dataset but since the dataset is large, we will work with only a subset to ensure that the solution is computationally feasible.\n",
        "\n",
        "**References:**\n",
        "\n",
        "* transforms.Compose (PyTorch): [Link](https://pytorch.org/vision/master/generated/torchvision.transforms.Compose.html)\n",
        "* Optuna (Hyperparameter Optimization Framework) [Link](https://optuna.readthedocs.io/en/stable/)"
      ],
      "metadata": {
        "id": "HS_V6StcOXOr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports and CUDA"
      ],
      "metadata": {
        "id": "PpUcw3m_gAdy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "z2ObSbddaDFv",
        "outputId": "3fa8b2d2-23b2-457d-d9a9-6a10d7f0378b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.1.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.36)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.6)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Downloading optuna-4.1.0-py3-none-any.whl (364 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m364.4/364.4 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.14.0-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.6 alembic-1.14.0 colorlog-6.9.0 optuna-4.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "from torchvision import datasets, transforms\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import optuna\n",
        "import random\n",
        "\n",
        "# Check if CUDA (GPU) is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "Nv9L_r8yOjoo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d30d4630-2fdf-46d8-c6d4-7b00c7613521"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "65TpZ6z3YVcT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset Overview**\n",
        "\n",
        "* Dataset: FashionMNIST\n",
        "* Classes: 10 (e.g., T-shirts, trousers, shoes)\n",
        "* Training Images: Subset of 10,000 (randomly sampled from 60,000)\n",
        "* Test Images: Subset of 2,000 (randomly sampled from 10,000)"
      ],
      "metadata": {
        "id": "nBrkVANZOnea"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "MJiS4LzoYWh9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step1**: Load and Sample the Dataset\n",
        "\n",
        "* Load the FashionMNIST dataset using torchvision.datasets.\n",
        "* Sample 10,000 images for training and 2,000 images for testing.\n",
        "* Normalize the pixel values to the range [-1, 1].\n",
        "* Create PyTorch DataLoaders for the training and test sets."
      ],
      "metadata": {
        "id": "caIjvjTMOuKb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ESYRM7JK-UW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2991ec3-8098-49e5-920f-7e37dc625794"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:01<00:00, 15.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 269kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.42M/4.42M [00:00<00:00, 5.06MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 5.62MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Transform: Normalize and convert to tensor\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))  # Centers the pixel values around 0 and scales them to [-1, 1]\n",
        "])\n",
        "\n",
        "# Load FashionMNIST dataset\n",
        "\n",
        "dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "\n",
        "\n",
        "# Sample the datset\n",
        "\n",
        "train_subset_size = 10000\n",
        "test_subset_size = 2000\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Key Insight:**\n",
        "\n",
        "* Sampling a smaller subset reduces computational cost, making it feasible for learners.\n",
        "* Normalizing to [-1, 1] helps the model converge faster and avoid numerical instability.\n"
      ],
      "metadata": {
        "id": "lLQCnqgQgINH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "S9NJ-ejsYYU7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step2**: Create Dataloaders\n",
        "\n",
        "* batch size = 32\n"
      ],
      "metadata": {
        "id": "wbAUaSPmSfsZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_subset, _ = random_split(dataset, [train_subset_size, len(dataset) - train_subset_size])\n",
        "test_subset, _ = random_split(test_dataset, [test_subset_size, len(test_dataset) - test_subset_size])"
      ],
      "metadata": {
        "id": "US239seqaZGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_subset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "Hz00fg0sSqT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Training data size: {len(train_subset)}\")\n",
        "print(f\"Testing data size: {len(test_subset)}\")"
      ],
      "metadata": {
        "id": "oq15WEfhS1HV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "757a5b25-df6b-4453-e495-100c668efac1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data size: 10000\n",
            "Testing data size: 2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Key Insights**\n",
        "\n",
        "* `random_split` is a PyTorch utility that randomly divides a dataset into two subsets.\n",
        "* The first subset will have `size1` samples, and the second subset will have `size2` samples."
      ],
      "metadata": {
        "id": "AuzZ2SdqhJvm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "1dSLUp9EYaG9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step3**: Define the Neural Network\n",
        "\n",
        "* Create a fully connected feed-forward neural network (no CNN).\n",
        "\n",
        "Structure:\n",
        "* Input layer: 784 neurons (28x28 image flattened).\n",
        "* 1st hidden layer: 128 neurons with ReLU activation.\n",
        "* 2nd hidden layer: 64 neurons with ReLU activation.\n",
        "* Output layer: 10 neurons (one for each class) with Softmax activation.\n",
        "\n",
        "Use `nn.Sequential`"
      ],
      "metadata": {
        "id": "bGRSPjG0StuU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FashionNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FashionNN, self).__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Flatten(),          # Flatten the input tensor\n",
        "            nn.Linear(28*28, 128), # Input layer (784)\n",
        "            nn.ReLU(),             # Activation\n",
        "            nn.Linear(128, 64),    # Hidden layer 1\n",
        "            nn.ReLU(),             # Activation\n",
        "            nn.Linear(64, 10),     # Output layer (10 classes)\n",
        "            nn.Softmax(dim=1)      # Softmax for probabilities\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)  # No need for explicit flattening\n",
        "\n"
      ],
      "metadata": {
        "id": "QJYOKAZmTpkb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9508c6c1-e9e7-4e91-b0ab-e6f30ca5b821"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FashionNN(\n",
            "  (network): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=64, out_features=10, bias=True)\n",
            "    (5): Softmax(dim=1)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Key Insight**\n",
        "\n",
        "* Flattening 28x28 images to 784 ensures compatibility with linear layers.\n"
      ],
      "metadata": {
        "id": "WmmmOsEPhUsx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "UJmkGAINYb0C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3**: Train the Base Model\n",
        "\n",
        "Instructions:\n",
        "\n",
        "Set the following base hyperparameters:\n",
        "* Loss function: Cross Entropy Loss\n",
        "* Learning rate: 0.01\n",
        "* Batch size: 32\n",
        "* Optimizer: SGD\n",
        "* Epochs: 100\n",
        "\n",
        "Train the model and record the training/validation accuracy and loss.\n"
      ],
      "metadata": {
        "id": "PNO5O1W_UI7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loss function and optimizer\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = 0.0\n",
        "    model.train()  # Set model to training mode\n",
        "    for images, labels in train_loader:\n",
        "        # Zero gradients\n",
        "        optimizer.zero_grad()\n",
        "        # Forward pass\n",
        "        predictions = model(images)\n",
        "        loss = loss_function(predictions, labels)\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # Append the training loss\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {train_loss/len(train_loader):.4f}\")\n"
      ],
      "metadata": {
        "id": "Mb5gFuiUUTDC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "003fa121-3dc5-4ac6-9f30-3c1e103c900e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100, Loss: 2.2045\n",
            "Epoch 2/100, Loss: 2.1812\n",
            "Epoch 3/100, Loss: 2.1578\n",
            "Epoch 4/100, Loss: 2.1284\n",
            "Epoch 5/100, Loss: 2.0950\n",
            "Epoch 6/100, Loss: 2.0648\n",
            "Epoch 7/100, Loss: 2.0385\n",
            "Epoch 8/100, Loss: 2.0141\n",
            "Epoch 9/100, Loss: 1.9938\n",
            "Epoch 10/100, Loss: 1.9707\n",
            "Epoch 11/100, Loss: 1.9490\n",
            "Epoch 12/100, Loss: 1.9320\n",
            "Epoch 13/100, Loss: 1.9164\n",
            "Epoch 14/100, Loss: 1.9005\n",
            "Epoch 15/100, Loss: 1.8877\n",
            "Epoch 16/100, Loss: 1.8756\n",
            "Epoch 17/100, Loss: 1.8655\n",
            "Epoch 18/100, Loss: 1.8559\n",
            "Epoch 19/100, Loss: 1.8465\n",
            "Epoch 20/100, Loss: 1.8374\n",
            "Epoch 21/100, Loss: 1.8280\n",
            "Epoch 22/100, Loss: 1.8191\n",
            "Epoch 23/100, Loss: 1.8107\n",
            "Epoch 24/100, Loss: 1.8026\n",
            "Epoch 25/100, Loss: 1.7973\n",
            "Epoch 26/100, Loss: 1.7890\n",
            "Epoch 27/100, Loss: 1.7838\n",
            "Epoch 28/100, Loss: 1.7782\n",
            "Epoch 29/100, Loss: 1.7755\n",
            "Epoch 30/100, Loss: 1.7686\n",
            "Epoch 31/100, Loss: 1.7662\n",
            "Epoch 32/100, Loss: 1.7608\n",
            "Epoch 33/100, Loss: 1.7582\n",
            "Epoch 34/100, Loss: 1.7558\n",
            "Epoch 35/100, Loss: 1.7538\n",
            "Epoch 36/100, Loss: 1.7512\n",
            "Epoch 37/100, Loss: 1.7479\n",
            "Epoch 38/100, Loss: 1.7456\n",
            "Epoch 39/100, Loss: 1.7415\n",
            "Epoch 40/100, Loss: 1.7388\n",
            "Epoch 41/100, Loss: 1.7396\n",
            "Epoch 42/100, Loss: 1.7374\n",
            "Epoch 43/100, Loss: 1.7343\n",
            "Epoch 44/100, Loss: 1.7311\n",
            "Epoch 45/100, Loss: 1.7290\n",
            "Epoch 46/100, Loss: 1.7274\n",
            "Epoch 47/100, Loss: 1.7276\n",
            "Epoch 48/100, Loss: 1.7254\n",
            "Epoch 49/100, Loss: 1.7232\n",
            "Epoch 50/100, Loss: 1.7203\n",
            "Epoch 51/100, Loss: 1.7196\n",
            "Epoch 52/100, Loss: 1.7177\n",
            "Epoch 53/100, Loss: 1.7167\n",
            "Epoch 54/100, Loss: 1.7140\n",
            "Epoch 55/100, Loss: 1.7127\n",
            "Epoch 56/100, Loss: 1.7099\n",
            "Epoch 57/100, Loss: 1.7098\n",
            "Epoch 58/100, Loss: 1.7093\n",
            "Epoch 59/100, Loss: 1.7072\n",
            "Epoch 60/100, Loss: 1.7060\n",
            "Epoch 61/100, Loss: 1.7050\n",
            "Epoch 62/100, Loss: 1.7027\n",
            "Epoch 63/100, Loss: 1.7028\n",
            "Epoch 64/100, Loss: 1.6999\n",
            "Epoch 65/100, Loss: 1.6978\n",
            "Epoch 66/100, Loss: 1.6974\n",
            "Epoch 67/100, Loss: 1.6951\n",
            "Epoch 68/100, Loss: 1.6956\n",
            "Epoch 69/100, Loss: 1.6945\n",
            "Epoch 70/100, Loss: 1.6916\n",
            "Epoch 71/100, Loss: 1.6924\n",
            "Epoch 72/100, Loss: 1.6917\n",
            "Epoch 73/100, Loss: 1.6892\n",
            "Epoch 74/100, Loss: 1.6879\n",
            "Epoch 75/100, Loss: 1.6867\n",
            "Epoch 76/100, Loss: 1.6845\n",
            "Epoch 77/100, Loss: 1.6852\n",
            "Epoch 78/100, Loss: 1.6832\n",
            "Epoch 79/100, Loss: 1.6826\n",
            "Epoch 80/100, Loss: 1.6809\n",
            "Epoch 81/100, Loss: 1.6802\n",
            "Epoch 82/100, Loss: 1.6789\n",
            "Epoch 83/100, Loss: 1.6790\n",
            "Epoch 84/100, Loss: 1.6768\n",
            "Epoch 85/100, Loss: 1.6746\n",
            "Epoch 86/100, Loss: 1.6749\n",
            "Epoch 87/100, Loss: 1.6730\n",
            "Epoch 88/100, Loss: 1.6730\n",
            "Epoch 89/100, Loss: 1.6711\n",
            "Epoch 90/100, Loss: 1.6702\n",
            "Epoch 91/100, Loss: 1.6698\n",
            "Epoch 92/100, Loss: 1.6669\n",
            "Epoch 93/100, Loss: 1.6652\n",
            "Epoch 94/100, Loss: 1.6643\n",
            "Epoch 95/100, Loss: 1.6642\n",
            "Epoch 96/100, Loss: 1.6616\n",
            "Epoch 97/100, Loss: 1.6601\n",
            "Epoch 98/100, Loss: 1.6617\n",
            "Epoch 99/100, Loss: 1.6583\n",
            "Epoch 100/100, Loss: 1.6577\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "jRX6sJn-iDbE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4**: Perform Hyperparameter Tuning\n",
        "Instructions:\n",
        "\n",
        "**Grid Search:**\n",
        "\n",
        "Hyperparameters:\n",
        "* Learning rate: [0.001, 0.01, 0.1]\n",
        "* Batch size: [32, 64]\n",
        "* Evaluate all combinations systematically."
      ],
      "metadata": {
        "id": "wZBFzIaZU3gU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define grid search parameters\n",
        "learning_rates = [0.001, 0.01, 0.1]\n",
        "batch_sizes = [32, 64]\n",
        "\n",
        "# Train and evaluate for all combinations\n",
        "best_loss = float('inf')\n",
        "best_params = {}\n",
        "\n",
        "for lr in learning_rates:\n",
        "    for batch_size in batch_sizes:\n",
        "        optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "        train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
        "        train_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            predictions = model(images)\n",
        "            loss = loss_function(predictions, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        avg_loss = train_loss / len(train_loader)\n",
        "        print(f\"LR: {lr}, Batch size: {batch_size}, Loss: {avg_loss:.4f}\")\n",
        "        if avg_loss < best_loss:\n",
        "            best_loss = avg_loss\n",
        "            best_params = {'lr': lr, 'batch_size': batch_size}\n",
        "\n",
        "print(f\"Best Params (Grid Search): {best_params}\")\n"
      ],
      "metadata": {
        "id": "TcJybSHKVSu1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f84780b4-1563-4981-cb58-8f012f4b18bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR: 0.001, Batch size: 32, Loss: 1.6560\n",
            "LR: 0.001, Batch size: 64, Loss: 1.6552\n",
            "LR: 0.01, Batch size: 32, Loss: 1.6562\n",
            "LR: 0.01, Batch size: 64, Loss: 1.6523\n",
            "LR: 0.1, Batch size: 32, Loss: 1.6715\n",
            "LR: 0.1, Batch size: 64, Loss: 1.6446\n",
            "Best Params (Grid Search): {'lr': 0.1, 'batch_size': 64}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Key Insight**\n",
        "\n",
        "* Grid search systematically tests all combinations, making it exhaustive but computationally expensive."
      ],
      "metadata": {
        "id": "ZXuP6Pfthf9Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "_P4D6kroiBPf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Search:**\n",
        "\n",
        "Randomly select hyperparameters for 5 trials from:\n",
        "* Learning rate: [0.0001, 0.001, 0.01, 0.1]\n",
        "* Batch size: [16, 32, 64, 128]"
      ],
      "metadata": {
        "id": "cZBDWk_wV3hB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define random search space\n",
        "learning_rates = [0.0001, 0.001, 0.01, 0.1]\n",
        "batch_sizes = [16, 32, 64, 128]\n",
        "\n",
        "# Randomly sample 5 combinations\n",
        "for _ in range(5):\n",
        "    lr = random.choice(learning_rates)\n",
        "    batch_size = random.choice(batch_sizes)\n",
        "    for batch_size in batch_sizes:\n",
        "        optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "        train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
        "        train_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            predictions = model(images)\n",
        "            loss = loss_function(predictions, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        avg_loss = train_loss / len(train_loader)\n",
        "        print(f\"LR: {lr}, Batch size: {batch_size}, Loss: {avg_loss:.4f}\")\n",
        "        if avg_loss < best_loss:\n",
        "            best_loss = avg_loss\n",
        "            best_params = {'lr': lr, 'batch_size': batch_size}\n",
        "\n",
        "print(f\"Best Params (Random Search): {best_params}\")\n"
      ],
      "metadata": {
        "id": "Tpbk9NjpV5GI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "065a656a-aecf-4791-9eb3-a827f9e6cbcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR: 0.01, Batch size: 16, Loss: 1.6302\n",
            "LR: 0.01, Batch size: 32, Loss: 1.6250\n",
            "LR: 0.01, Batch size: 64, Loss: 1.6229\n",
            "LR: 0.01, Batch size: 128, Loss: 1.6218\n",
            "LR: 0.0001, Batch size: 16, Loss: 1.6216\n",
            "LR: 0.0001, Batch size: 32, Loss: 1.6215\n",
            "LR: 0.0001, Batch size: 64, Loss: 1.6217\n",
            "LR: 0.0001, Batch size: 128, Loss: 1.6219\n",
            "LR: 0.1, Batch size: 16, Loss: 1.6645\n",
            "LR: 0.1, Batch size: 32, Loss: 1.6340\n",
            "LR: 0.1, Batch size: 64, Loss: 1.6196\n",
            "LR: 0.1, Batch size: 128, Loss: 1.6119\n",
            "LR: 0.01, Batch size: 16, Loss: 1.6078\n",
            "LR: 0.01, Batch size: 32, Loss: 1.6042\n",
            "LR: 0.01, Batch size: 64, Loss: 1.6036\n",
            "LR: 0.01, Batch size: 128, Loss: 1.6011\n",
            "LR: 0.1, Batch size: 16, Loss: 1.6449\n",
            "LR: 0.1, Batch size: 32, Loss: 1.6216\n",
            "LR: 0.1, Batch size: 64, Loss: 1.6047\n",
            "LR: 0.1, Batch size: 128, Loss: 1.5954\n",
            "Best Params (Random Search): {'lr': 0.1, 'batch_size': 128}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Key Insight**\n",
        "\n",
        "Random search can save time by sampling fewer combinations, though it might miss the best parameters."
      ],
      "metadata": {
        "id": "7rsU1HwfhnOR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "AVbmhx9jh_sw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bayesian Optimization (Optuna):**\n",
        "\n",
        "Use optuna.create_study to dynamically suggest:\n",
        "* Learning rate: Range (0.0001, 0.1)\n",
        "* Hidden layer neurons: Range (32, 256)"
      ],
      "metadata": {
        "id": "u46y5GicWU4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "\n",
        "def objective(trial):\n",
        "    # Suggest parameters\n",
        "    lr = trial.suggest_float('lr', 0.0001, 0.1)\n",
        "    neurons = trial.suggest_int('neurons', 32, 256)\n",
        "\n",
        "    # Modify model\n",
        "    model = nn.Sequential(\n",
        "        nn.Linear(28*28, neurons),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(neurons, 10),\n",
        "        nn.Softmax(dim=1)\n",
        "    )\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Train model\n",
        "    model.train()\n",
        "    num_epochs = 5  # Use a small number of epochs for faster Optuna runs\n",
        "    for epoch in range(num_epochs):\n",
        "        for images, labels in train_loader:\n",
        "            # Flatten images\n",
        "            images = images.view(images.size(0), -1)\n",
        "\n",
        "            # Forward pass\n",
        "            predictions = model(images)\n",
        "            loss = loss_function(predictions, labels)\n",
        "\n",
        "            # Backward pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # Evaluate on the validation set\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            # Flatten images\n",
        "            images = images.view(images.size(0), -1)\n",
        "\n",
        "            # Forward pass\n",
        "            predictions = model(images)\n",
        "            loss = loss_function(predictions, labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(test_loader)  # Average loss over all batches\n",
        "    return avg_loss  # Return loss for Optuna to minimize\n",
        "\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=10)\n",
        "print(f\"Best Params (Optuna): {study.best_params}\")\n"
      ],
      "metadata": {
        "id": "8pX7C-hQWYzu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c585b0bb-2fcc-4290-df31-bc14c733c706"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-29 21:09:26,339] A new study created in memory with name: no-name-82adcb41-9515-4399-b1f5-d5b4812a4f5e\n",
            "[I 2024-11-29 21:09:41,710] Trial 0 finished with value: 1.8321388297610812 and parameters: {'lr': 0.02829160173758147, 'neurons': 137}. Best is trial 0 with value: 1.8321388297610812.\n",
            "[I 2024-11-29 21:09:57,312] Trial 1 finished with value: 2.2904376378135076 and parameters: {'lr': 0.001887254181446645, 'neurons': 65}. Best is trial 0 with value: 1.8321388297610812.\n",
            "[I 2024-11-29 21:10:12,952] Trial 2 finished with value: 1.999411183690268 and parameters: {'lr': 0.01723889609970297, 'neurons': 174}. Best is trial 0 with value: 1.8321388297610812.\n",
            "[I 2024-11-29 21:10:28,324] Trial 3 finished with value: 2.046592748354352 and parameters: {'lr': 0.015377349910871915, 'neurons': 51}. Best is trial 0 with value: 1.8321388297610812.\n",
            "[I 2024-11-29 21:10:44,346] Trial 4 finished with value: 1.759322446490091 and parameters: {'lr': 0.06027340154476324, 'neurons': 248}. Best is trial 4 with value: 1.759322446490091.\n",
            "[I 2024-11-29 21:10:59,263] Trial 5 finished with value: 1.760380502731081 and parameters: {'lr': 0.0615006052741902, 'neurons': 119}. Best is trial 4 with value: 1.759322446490091.\n",
            "[I 2024-11-29 21:11:13,768] Trial 6 finished with value: 1.749889682209681 and parameters: {'lr': 0.07179060857487811, 'neurons': 63}. Best is trial 6 with value: 1.749889682209681.\n",
            "[I 2024-11-29 21:11:28,609] Trial 7 finished with value: 1.7368388913926625 and parameters: {'lr': 0.09295178735979277, 'neurons': 118}. Best is trial 7 with value: 1.7368388913926625.\n",
            "[I 2024-11-29 21:11:43,295] Trial 8 finished with value: 2.020007375686888 and parameters: {'lr': 0.013293811247138942, 'neurons': 122}. Best is trial 7 with value: 1.7368388913926625.\n",
            "[I 2024-11-29 21:11:58,460] Trial 9 finished with value: 1.7754252657057747 and parameters: {'lr': 0.04517739679766781, 'neurons': 239}. Best is trial 7 with value: 1.7368388913926625.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Params (Optuna): {'lr': 0.09295178735979277, 'neurons': 118}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Key Insight**\n",
        "\n",
        "Bayesian optimization efficiently searches hyperparameter space by learning from prior trials."
      ],
      "metadata": {
        "id": "sBQAZmhxhta3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "rhLh1t7LYnmj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step5**: Evaluate and Compare the Model\n",
        "\n",
        "* Train the model using the best hyperparameters from each method (Grid Search, Random Search, Optuna).\n",
        "* num_epochs = 50\n",
        "* Evaluate all models on the test set.\n",
        "* Plot training/validation accuracy and loss for the best model.\n"
      ],
      "metadata": {
        "id": "DAkXzAgHW9wQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model with best params and evaluate\n",
        "model = FashionNN()  # Re-initialize the model\n",
        "optimizer = optim.SGD(model.parameters(), lr=best_params['lr'])\n",
        "train_loader = DataLoader(train_subset, batch_size=best_params['batch_size'], shuffle=True)\n",
        "\n",
        "# Define loss function\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 50  # Re-train with best parameters\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = 0.0\n",
        "    model.train()  # Set model to training mode\n",
        "    for images, labels in train_loader:\n",
        "        # Clear previous gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        predictions = model(images)  # Forward pass\n",
        "\n",
        "        loss = loss_function(predictions, labels)    # Compute loss\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "\n",
        "        # Update weights\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {train_loss/len(train_loader):.4f}\")\n",
        "\n",
        "# Evaluate on test set\n",
        "model.eval()  # Set model to evaluation mode\n",
        "test_loss = 0.0\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():  # Disable gradient computation for evaluation\n",
        "    for images, labels in test_loader:\n",
        "        predictions =  model(images)          # Forward pass\n",
        "        loss = loss_function(predictions, labels)    # Compute loss\n",
        "        test_loss += loss.item()\n",
        "\n",
        "        # Calculate accuracy\n",
        "        _, predicted = torch.max(predictions, 1)  # Get class with highest probability\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "# Print test loss and accuracy\n",
        "print(f\"Test Loss: {test_loss/len(test_loader):.4f}\")\n",
        "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "id": "aMRSKltYXPTD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9251072-d50c-4f03-c86c-0daf2e816899"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Loss: 2.2900\n",
            "Epoch 2/50, Loss: 2.1458\n",
            "Epoch 3/50, Loss: 1.9093\n",
            "Epoch 4/50, Loss: 1.7884\n",
            "Epoch 5/50, Loss: 1.7504\n",
            "Epoch 6/50, Loss: 1.7309\n",
            "Epoch 7/50, Loss: 1.7183\n",
            "Epoch 8/50, Loss: 1.7087\n",
            "Epoch 9/50, Loss: 1.7000\n",
            "Epoch 10/50, Loss: 1.6943\n",
            "Epoch 11/50, Loss: 1.6883\n",
            "Epoch 12/50, Loss: 1.6872\n",
            "Epoch 13/50, Loss: 1.6801\n",
            "Epoch 14/50, Loss: 1.6769\n",
            "Epoch 15/50, Loss: 1.6747\n",
            "Epoch 16/50, Loss: 1.6704\n",
            "Epoch 17/50, Loss: 1.6679\n",
            "Epoch 18/50, Loss: 1.6661\n",
            "Epoch 19/50, Loss: 1.6620\n",
            "Epoch 20/50, Loss: 1.6615\n",
            "Epoch 21/50, Loss: 1.6601\n",
            "Epoch 22/50, Loss: 1.6602\n",
            "Epoch 23/50, Loss: 1.6579\n",
            "Epoch 24/50, Loss: 1.6572\n",
            "Epoch 25/50, Loss: 1.6564\n",
            "Epoch 26/50, Loss: 1.6557\n",
            "Epoch 27/50, Loss: 1.6505\n",
            "Epoch 28/50, Loss: 1.6502\n",
            "Epoch 29/50, Loss: 1.6494\n",
            "Epoch 30/50, Loss: 1.6512\n",
            "Epoch 31/50, Loss: 1.6505\n",
            "Epoch 32/50, Loss: 1.6530\n",
            "Epoch 33/50, Loss: 1.6442\n",
            "Epoch 34/50, Loss: 1.6435\n",
            "Epoch 35/50, Loss: 1.6430\n",
            "Epoch 36/50, Loss: 1.6439\n",
            "Epoch 37/50, Loss: 1.6432\n",
            "Epoch 38/50, Loss: 1.6436\n",
            "Epoch 39/50, Loss: 1.6405\n",
            "Epoch 40/50, Loss: 1.6417\n",
            "Epoch 41/50, Loss: 1.6384\n",
            "Epoch 42/50, Loss: 1.6378\n",
            "Epoch 43/50, Loss: 1.6361\n",
            "Epoch 44/50, Loss: 1.6364\n",
            "Epoch 45/50, Loss: 1.6353\n",
            "Epoch 46/50, Loss: 1.6367\n",
            "Epoch 47/50, Loss: 1.6357\n",
            "Epoch 48/50, Loss: 1.6338\n",
            "Epoch 49/50, Loss: 1.6324\n",
            "Epoch 50/50, Loss: 1.6318\n",
            "Test Loss: 1.6863\n",
            "Test Accuracy: 77.10%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "n4LgAqQ1Yo7_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step6**: Visualize the Model"
      ],
      "metadata": {
        "id": "e0sNkV7nYsZf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get predictions\n",
        "model.eval()\n",
        "images, labels = next(iter(test_loader))\n",
        "predictions = model(images).argmax(dim=1)\n",
        "\n",
        "# Plot 9 images\n",
        "for i in range(9):\n",
        "    plt.subplot(3, 3, i+1)\n",
        "    plt.imshow(images[i].squeeze(), cmap='gray')\n",
        "    plt.title(f\"Pred: {predictions[i]}, True: {labels[i]}\")\n",
        "    plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "W1TNb1LaYwq1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "8e0f8883-facc-4a73-a13f-951e6eafd15e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "lDRmGut-juXc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BONUS**: Play with hyperparameters of the models and test the accuracy."
      ],
      "metadata": {
        "id": "Ju6zJ_Mch2OU"
      }
    }
  ]
}