{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c888377",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">Codebasics DL Course: Next Word Prediction Using GPT2</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e492ca",
   "metadata": {},
   "source": [
    "### Transformers pipeline"
   ]
  },
  {
   "cell_type": "code",
   "id": "67fc8bbc",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2026-01-06T04:47:27.923201Z",
     "start_time": "2026-01-06T04:45:49.696577Z"
    }
   },
   "source": [
    "import torch\n",
    "from transformers import pipeline, set_seed\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "set_seed(42)\n",
    "generator(\"Happiness lies within and\", max_length=30, num_return_sequences=5)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saurabhsule/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Device set to use mps:0\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"Happiness lies within and is not in the heart of the whole person. That's why you should never put the heart of an individual's life in the hands of anyone else.\\n\\nPeople are too busy with the same problems to be able to do things together. The problem with this is that it is a distraction. You are busy with your own life, not with the needs of others. You are busy with your own ego, not with the needs of others.\\n\\nAnd while I understand that your ego is what you give to others, it is not what you give to yourself. If you have a big ego, you will be able to do things with it, but if you have a small ego, you will be unable to do things.\\n\\nI believe that ego is not a good thing. When you look at the world and feel the need to do certain things, you are not doing them right. It is not how you are, it is who you are.\\n\\nYou are making decisions that are not right, and you do not feel like doing them right. You are making decisions that are not right, and you do not feel like doing them wrong. The ego is not a good thing, but you are making decisions that are not right, and you do\"},\n",
       " {'generated_text': 'Happiness lies within and is the product of self-sacrifice; it is the result of the struggle for existence by the world, and hence of the struggle for love. Its nature is the struggle for love, and it is the result of our struggle for love, it is the result of the struggle for love; it is the result of the struggle for love, for a good life. It is the result of the battle for the love of the world, for a good life, and so on.\\n\\nThere is only one kind of happiness – the happiness of the people in happiness. It is the happiness of a people, and the happiness of a world which is without suffering, which is without suffering, which is without suffering. It is a happiness of the people in the world.\\n\\nThere is only one kind of happiness: the happiness of people in the world. It is the happiness of the people in the world.\\n\\nIn the last sentence, my point is that happiness is a measure of the happiness of the people in the world. Here, I think, the distinction between happiness and happiness is clear: happiness is a measure of the happiness of the people in the world. Here, I think, happiness is a measure of the happiness of the people in the world.'},\n",
       " {'generated_text': 'Happiness lies within and beyond every person, from the smallest to the largest. It is the life of the soul without the ego, without the ego without the ego.\\n\\nThe ego is the most beautiful thing of all, the most beautiful thing in the world and the most beautiful thing in the universe.\\n\\nThe ego is the power of all things, the power of all life. It is the power of God, the power of the Creator, the power of the Holy Spirit.\\n\\nThe ego is the power of all things. It is the power of God, the power of the Creator, the power of the Holy Spirit.\\n\\nThe ego and the personality are the same, the personality is the power of all things.\\n\\nThe ego and the personality are the same, the personality is the power of all things.\\n\\nThe ego and the personality are the same, the personality is the power of all things.\\n\\nThe ego and the personality are the same, the personality is the power of all things.\\n\\nThe ego and the personality are the same, the personality is the power of all things.\\n\\nThe ego and the personality are the same, the personality is the power of all things.\\n\\nThe ego and the personality are the same,'},\n",
       " {'generated_text': 'Happiness lies within and outside of a good person.\\n\\nThe ability to think is a central element of a good person.\\n\\nBeing around people is a central element of a good person.\\n\\nBeing with people is a central element of a good person.\\n\\nBeing with people is a central element of a good person.\\n\\nBeing with people is a central element of a good person.\\n\\nBeing with people is a central element of a good person.\\n\\nBeing with people is a central element of a good person.\\n\\nBeing with people is a central element of a good person.\\n\\nBeing with people is a central element of a good person.\\n\\nBeing with people is a central element of a good person.\\n\\nBeing with people is a central element of a good person.\\n\\nBeing with people is a central element of a good person.\\n\\nBeing with people is a central element of a good person.\\n\\nBeing with people is a central element of a good person.\\n\\nBeing with people is a central element of a good person.\\n\\nBeing with people is a central element of a good person.\\n\\nBeing with people is a central element of a good person.\\n\\nBeing with people is a central element of a'},\n",
       " {'generated_text': 'Happiness lies within and between us.\\n\\nWe are the best of the best.\\n\\nWe are the ones who inspire others to learn.\\n\\nWe are the ones who help others grow into greatness.\\n\\nWe are the ones who give the other a chance.\\n\\nWe are the ones who make others feel grateful for their talents.\\n\\nWe are the ones who inspire others to be the best of them.\\n\\nWe are the ones who make others feel good about themselves.\\n\\nWe are the ones who make others feel special.\\n\\nWe are the ones who make others feel happy.\\n\\nWe are the ones who inspire others to be happy.\\n\\nWe are the ones who inspire others to be happy.\\n\\nWe are the ones who inspire others to be happy.\\n\\nWe are the ones who inspire others to be happy.\\n\\nWe are the ones who inspire others to be happy.\\n\\nWe are the ones who inspire others to be happy.\\n\\nWe are the ones who inspire others to be happy\\n\\nWe are the ones who inspire others to be happy\\n\\nWe are the ones who inspire others to be happy\\n\\nWe are the ones who inspire others to be happy\\n\\nWe are the ones who inspire others to'}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "4850f586",
   "metadata": {},
   "source": [
    "### GPT2 Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "id": "b96cca01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T04:52:22.096037Z",
     "start_time": "2026-01-06T04:52:19.473244Z"
    }
   },
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "prompt = \"Apollo 11 was the first crewed\"\n",
    "inputs = tokenizer(prompt, return_tensors='pt')\n",
    "inputs"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[25189, 15578,  1367,   373,   262,   717,  5462,   276]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "e769f61b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T04:52:38.076481Z",
     "start_time": "2026-01-06T04:52:38.067571Z"
    }
   },
   "source": [
    "tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ap', 'ollo', 'Ġ11', 'Ġwas', 'Ġthe', 'Ġfirst', 'Ġcrew', 'ed']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "0a498262",
   "metadata": {},
   "source": [
    "### GPT2  Model for Next Word Prediction"
   ]
  },
  {
   "cell_type": "code",
   "id": "01e13474",
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2026-01-06T04:52:43.850900Z",
     "start_time": "2026-01-06T04:52:41.317141Z"
    }
   },
   "source": [
    "from transformers import GPT2LMHeadModel\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "outputs = model(**inputs)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "6d706066",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T04:52:55.165324Z",
     "start_time": "2026-01-06T04:52:55.160480Z"
    }
   },
   "source": [
    "logits = outputs.logits\n",
    "logits.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 50257])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "63b9736d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T04:52:56.744553Z",
     "start_time": "2026-01-06T04:52:56.723181Z"
    }
   },
   "source": [
    "last_token_logits = logits[:, -1, :]\n",
    "last_token_logits "
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-111.3245, -110.2130, -117.3254,  ..., -121.1637, -116.9986,\n",
       "         -111.5559]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "a2ef9663",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T04:52:59.212257Z",
     "start_time": "2026-01-06T04:52:59.207423Z"
    }
   },
   "source": [
    "next_token_id = torch.argmax(last_token_logits).item()\n",
    "next_token_id"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4365"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "e2f8c2eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T04:53:01.359902Z",
     "start_time": "2026-01-06T04:53:01.350843Z"
    }
   },
   "source": [
    "tokenizer.decode(next_token_id)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' mission'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
