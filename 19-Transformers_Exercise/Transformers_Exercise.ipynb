{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Problem Statement: **AtliQ's Social Media Monitoring for COVID-19 Insights using BERT**\n",
        "\n",
        "### AtliQ is launching a social media monitoring system to identify tweets related to COVID-19, aiming to track trends, misinformation, and public sentiment. Your task is to fine-tune a pre-trained BERT model using PyTorch to classify whether a given tweet is about COVID-19 or not.\n",
        "\n",
        "**References:**\n",
        "\n",
        "1. **Attention is All you Need:** [Click Here](https://arxiv.org/abs/1706.03762)\n",
        "\n",
        "2. **BERT:** [Click Here](https://arxiv.org/abs/1810.04805)\n",
        "\n"
      ],
      "metadata": {
        "id": "ij6oyWf5v0Yf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "6EvRmT5FwULP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports and CUDA"
      ],
      "metadata": {
        "id": "sbmeJcDWuCHn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faxxMOzMMa5O",
        "outputId": "01bcdc16-8413-4bc2-d60e-2f0b993ccfb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset, random_split\n",
        "from torchvision import datasets, transforms\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import random\n",
        "from tqdm.notebook import tqdm\n",
        "from transformers import BertForSequenceClassification\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Check if CUDA (GPU) is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step1:** Dataset Overview\n",
        "\n",
        "* We use **covid_twitter_dataset_codebasics_DL** dataset which has 5287 rows.\n",
        "* Columns: ID, text and target\n",
        "* The feature column (text) contains the tweet content, and the target column (target) contains the binary labels indicating whether a tweet is COVID-19-related (**1**) or not (**0**).\n"
      ],
      "metadata": {
        "id": "1-J7ECFzwVpH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = # code here\n",
        "data.head()"
      ],
      "metadata": {
        "id": "IspKKeW0MpRw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "1W_rVH5qw_fY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "DA54uIDayjAC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step2:** Split the dataset\n",
        "\n",
        "* Train:Test :: 70:30"
      ],
      "metadata": {
        "id": "jxju6d9xxpai"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "-4jxmEQZyj8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_X, test_X, train_Y, test_Y = # code here"
      ],
      "metadata": {
        "id": "RjHDhskFM2Tk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step3:** Tokenization\n",
        "\n",
        "* The AutoTokenizer from the Hugging Face library is used to load the pre-trained BERT tokenizer (bert-base-cased).\n"
      ],
      "metadata": {
        "id": "xeR071x6yxY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
      ],
      "metadata": {
        "id": "JnG8WHNENEgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_tokens = tokenizer(list(train_X), padding = True, truncation=True)\n",
        "test_tokens = # code here"
      ],
      "metadata": {
        "id": "TXVgSTHqNX_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_tokens.keys()"
      ],
      "metadata": {
        "id": "i-W2a_y9Nj6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_tokens['input_ids'][0])\n",
        "print(tokenizer.decode(train_tokens['input_ids'][0]))"
      ],
      "metadata": {
        "id": "9_-UV6_eNmhO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "nFf6B70IcRk0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step4**: Create a dataset class\n",
        "* Implement a custom TokenData class inheriting from torch.utils.data.Dataset.\n",
        "* Use the train argument to toggle between training (train_tokens, train_Y) and testing datasets (test_tokens, test_Y).\n",
        "* Define __len__ to return the dataset length and __getitem__ to provide tokenized inputs (input_ids, attention_mask) and labels (labels) as tensors.\n",
        "* Ensure the class works correctly by retrieving a sample and verifying the output format."
      ],
      "metadata": {
        "id": "1vCUvn0CcSfZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TokenData(Dataset):\n",
        "    def __init__(self, train = False):\n",
        "        if train:\n",
        "            self.text_data = train_X\n",
        "            self.tokens = train_tokens\n",
        "            self.labels = list(train_Y)\n",
        "        else:\n",
        "            self.text_data = test_X\n",
        "            self.tokens = test_tokens\n",
        "            self.labels = list(test_Y)\n",
        "\n",
        "    def __len__(self):\n",
        "        # code here\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = {}\n",
        "        for k, v in self.tokens.items():\n",
        "            sample[k] = torch.tensor(v[idx])\n",
        "        sample['labels'] = torch.tensor(self.labels[idx])\n",
        "        return sample"
      ],
      "metadata": {
        "id": "rI1s_tixN6Cy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "dBonK0IScVF8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step5**: Create Dataloaders\n",
        "\n",
        "* Initialize the `TokenData` class to create train_dataset and test_dataset objects for training and testing datasets.\n",
        "* Set `batch_size=30` and enable shuffling for the training dataset to improve model generalization.\n",
        "* Verify that train_loader and test_loader correctly return batches of tokenized inputs and labels."
      ],
      "metadata": {
        "id": "unRFzzTecV62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 30\n",
        "train_dataset = # code here\n",
        "test_dataset = # code here\n",
        "\n",
        "train_loader = # code here\n",
        "test_loader = # code here"
      ],
      "metadata": {
        "id": "Sr5VRe0kN9Ub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ewX-Bqb9caOv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step6:** Define Model\n",
        "*  Use `BertForSequenceClassification` with `bert-base-cased` to load a pre-trained BERT model for sequence classification tasks.\n",
        "* Use `AdamW` optimizer with a learning rate of `1e-5` to fine-tune the model parameters. This optimizer is well-suited for transformer-based models.\n",
        "* Use `CrossEntropyLoss` to compute the loss for multi-class classification (as the dataset contains two classes)."
      ],
      "metadata": {
        "id": "gZT2z96dcYUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model =  # code here\n",
        "optimizer = # code here\n",
        "loss_fn = # code here"
      ],
      "metadata": {
        "id": "fRvsF9oJOCBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "T3U1ees-cbgA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* num_eochs = 3\n",
        "* Use bert_model.to(device) to move the model to a GPU if available, or keep it on the CPU. This ensures efficient computation, especially for large datasets or models like BERT."
      ],
      "metadata": {
        "id": "AhJGyZjxccZa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs =\n",
        "bert_model.to(device) # Transfer model to GPU if available"
      ],
      "metadata": {
        "id": "J1QoUC-8OOvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "7weERW42ckLw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step7:** Model Training"
      ],
      "metadata": {
        "id": "UY0aqY4Qcf_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    bert_model.train()\n",
        "    total_train_loss = 0.0  # Initialize total loss for each epoch\n",
        "\n",
        "    for i, batch in enumerate(train_loader):\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "        # Set gradients to zero\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Pass data to the model\n",
        "        outputs = bert_model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'])\n",
        "\n",
        "        # Get logits and calculate the loss\n",
        "        pred = outputs.logits\n",
        "        loss = # code here\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "\n",
        "        # Optimizing model parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        # Accumulate the loss for the epoch\n",
        "        total_train_loss += # code here\n",
        "\n",
        "    # Calculate and log the average loss for the epoch\n",
        "    avg_train_loss = # code here\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs} - Training Loss: {avg_train_loss:.4f}\")\n"
      ],
      "metadata": {
        "id": "yN-7EqSpOZvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "JuK0Fa9ocle6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step8:** Model Evaluation"
      ],
      "metadata": {
        "id": "aj8C8_-RcmQI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set model to evaluation mode\n",
        "bert_model.eval()\n",
        "\n",
        "# Variables for tracking accuracy and loss\n",
        "correct = 0\n",
        "total = 0\n",
        "total_test_loss = 0.0\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "# Disable gradient computation during testing\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = bert_model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'])\n",
        "\n",
        "        # Get logits\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = # code here\n",
        "        total_test_loss += # code here\n",
        "\n",
        "        # Get predictions\n",
        "        preds = logits.argmax(dim=1)\n",
        "\n",
        "        # Update the correct count and total number of samples\n",
        "        correct += (preds == batch['labels']).sum().item()\n",
        "        total += batch['labels'].size(0)\n",
        "\n",
        "        # Store predictions and labels for confusion matrix\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(batch['labels'].cpu().numpy())\n",
        "\n",
        "# Calculate the average test loss\n",
        "avg_test_loss = # code here\n",
        "\n",
        "# Calculate overall accuracy\n",
        "accuracy = # code here\n",
        "\n",
        "# Print overall results\n",
        "print(f\"Test Set - Loss: {avg_test_loss:.4f}, Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "TK-wiYwBVeNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BONUS**: Visualize the Confusion Matrix"
      ],
      "metadata": {
        "id": "WN_IoRS1Fcqx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "EtBWNt8ZEu_1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step9**: Inference with new Tweets\n",
        "\n",
        "* Run this inference code to predict the output for test_tweets"
      ],
      "metadata": {
        "id": "Fxk8JzEWLJvh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test tweets\n",
        "test_tweets = [\n",
        "    \"The number of COVID-19 cases has increased in the past week.\",\n",
        "    \"Just watched an amazing sunset at the beach!\",\n",
        "    \"New vaccination centers are opening up to combat the spread of coronavirus.\",\n",
        "    \"A virus has impacted the global ecosystem a lot\",\n",
        "    \"India lost the match againt Australia at Adelaide\"\n",
        "]\n",
        "\n",
        "# Predict function for a single tweet\n",
        "def predict_tweet(tweet_text):\n",
        "    # Tokenize\n",
        "    tokens = tokenizer(tweet_text, padding=True, truncation=True, return_tensors='pt')\n",
        "    tokens = {k: v.to(device) for k, v in tokens.items()}\n",
        "\n",
        "    # Predict\n",
        "    bert_model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = bert_model(**tokens)\n",
        "        probs = torch.softmax(outputs.logits, dim=1)\n",
        "        prediction = torch.argmax(probs, dim=1)\n",
        "\n",
        "    return {\n",
        "        'text': tweet_text,\n",
        "        'is_covid': bool(prediction.item()),\n",
        "        'confidence': probs[0][prediction[0]].item() * 100\n",
        "    }\n",
        "\n",
        "# Make predictions for test tweets\n",
        "print(\"Sample Tweet Predictions:\\n\")\n",
        "for tweet in test_tweets:\n",
        "    result = predict_tweet(tweet)\n",
        "    print(f\"Tweet: {result['text']}\")\n",
        "    print(f\"Prediction: {'COVID-related' if result['is_covid'] else 'Not COVID-related'}\")\n",
        "    print(f\"Confidence: {result['confidence']:.2f}%\")\n",
        "    print(\"-\" * 50 + \"\\n\")"
      ],
      "metadata": {
        "id": "qIV_feNNLO9X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}