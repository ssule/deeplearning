{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Problem Statement: **CNN-Based Fashion Classification by AtliQ**\n",
        "\n",
        "### AtliQ is launching a state-of-the-art \"**Fashion Classification System**\" to automatically identify clothing items and accessories from images. The goal is to build a Convolutional Neural Network (CNN) model that can classify images from the **FashionMNIST** dataset into one of its 10 categories. You'll implement an end-to-end solution using PyTorch, covering dataset preparation, CNN construction, training, evaluation, and visualization.\n"
      ],
      "metadata": {
        "id": "9VruyGJ_zfPG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports and CUDA"
      ],
      "metadata": {
        "id": "Yxf7G43e0tgR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "from torchvision import datasets, transforms\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n"
      ],
      "metadata": {
        "id": "1Qxi1T-q_bFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "TwtIHzW20y8P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step1**: Dataset Overview\n",
        "\n",
        "Load the **FashionMNIST dataset** and extract a smaller subset for training and testing.\n",
        "\n",
        "Details:\n",
        "* Fashion-MNIST is a dataset of Zalando's article imagesâ€”consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes.\n",
        "\n",
        "* Use **10,000 images for training** and **3,000 images for testing** by randomly sampling from the dataset.\n",
        "* Apply transformations such as random horizontal flips and random cropping for data augmentation during training.\n",
        "* Normalize the pixel values to have a mean of 0 and standard deviation of 1 for faster convergence.\n",
        "* Use `batch size = 64` for trainloader and testloader\n",
        "\n",
        "\n",
        "Use torch.utils.data.random_split to partition the data into the desired subset sizes."
      ],
      "metadata": {
        "id": "zppSMYgX08ie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(28, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])  # Single-channel mean and std\n",
        "])\n",
        "\n",
        "# Load FashionMNIST dataset\n",
        "dataset = # Code Here\n",
        "\n",
        "test_dataset = # Code Here\n",
        "\n",
        "# Subset the dataset (use random_split)\n",
        "train_subset_size, test_subset_size = # Code Here\n",
        "train_subset, _ = # Code Here\n",
        "test_subset, _ = # Code Here\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = # Code Here\n",
        "test_loader = # Code Here\n"
      ],
      "metadata": {
        "id": "xxXIT8TP0z0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "TrJ-_FZOvjia"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step2** :Visualizing the Dataset\n",
        "\n",
        "Let's visualize some sample images with their class labels.\n",
        "\n",
        "Details:\n",
        "* Create a 4x4 grid of 16 images from the training dataset.\n",
        "* Include the class labels (e.g., 0, 1, 2, 3 etc.) under each image\n",
        "\n",
        "Label-Image Description:\n",
        "* 0: T-shirt/top\n",
        "* 1: Trouser\n",
        "* 2: Pullover\n",
        "* 3: Dress\n",
        "* 4: Coat\n",
        "* 5: Sandal\n",
        "* 6: Shirt\n",
        "* 7: Sneaker\n",
        "* 8: Bag\n",
        "* 9: Ankle boot"
      ],
      "metadata": {
        "id": "A53p82Gf2tKP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classes = dataset.classes\n",
        "# Retrieve a batch of data from the DataLoader\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "print(type(images))\n",
        "print(images.shape)\n",
        "print(labels.shape)\n"
      ],
      "metadata": {
        "id": "BZzSPDos2_PP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "BAVQz29-vmjF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize a 4x4 grid of 16 images from the DataLoader\n",
        "images, labels = next(iter(train_loader))\n",
        "\n",
        "fig, axes = plt.subplots(4, 4, figsize=(8, 8))\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(images[i][0].numpy(), cmap='gray')  # Display image\n",
        "    ax.set_title(f\"Label: {labels[i].item()}\")\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "s4HWj4KhtSJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "e-gv3gMAtTVy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step3**: Constructing the CNN Model\n",
        "\n",
        "Let's build a convolutional neural network to classify FashionMNIST images.\n",
        "\n",
        "**Details:**\n",
        "\n",
        "* Use two convolutional layers followed by pooling, activation functions (ReLU), and fully connected layers.\n",
        "\n",
        "**CNN components:**\n",
        "* Convolutions: To extract spatial features from images.\n",
        "* Pooling: To reduce dimensionality while retaining important information.\n",
        "* Padding: To maintain image dimensions after convolutions.\n",
        "* Strides: To control the movement of the kernel over the image.\n",
        "\n",
        "**Architecture:**\n",
        "\n",
        "* Conv1: Input channels = 1, Output channels = 32, Kernel size = 3x3, Activation = ReLU.\n",
        "* Conv2: Input channels = 32, Output channels = 64, Kernel size = 3x3, Activation = ReLU.\n",
        "* MaxPooling: Kernel size = 2x2, Stride = 2.\n",
        "\n",
        "Fully Connected Layers:\n",
        "* Input = 64*7*7, Output = 128, Activation = ReLU, Dropout = 0.5.\n",
        "* Output = 10 (number of classes)."
      ],
      "metadata": {
        "id": "BLjZtmIl3F-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FashionMNISTCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FashionMNISTCNN, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            # Conv block 1\n",
        "\n",
        "            # ReLU\n",
        "\n",
        "            # MaxPool\n",
        "\n",
        "            # Conv block 2\n",
        "\n",
        "            # ReLU\n",
        "\n",
        "            # MaxPool\n",
        "        )\n",
        "\n",
        "        # Flatten Layer\n",
        "\n",
        "        # Fully Connected Layers (Classifier)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(64 * 7 * 7, 128),  # 64 channels, 7x7 feature map size after pooling\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),  # Dropout for regularization\n",
        "            nn.Linear(128, 10),  # 10 output classes (for FashionMNIST)\n",
        "            nn.LogSoftmax(dim=1)  # LogSoftmax for probabilistic output\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the Model\n",
        "model = # Code Here\n",
        "\n",
        "# Print the model architecture\n"
      ],
      "metadata": {
        "id": "PZBJLtSq3g9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "7wAa5HA65ENJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5**: Defining Loss Function and Optimizer\n",
        "\n",
        "Now we'll establish the optimization and evaluation criteria for training.\n",
        "\n",
        "**Details:**\n",
        "\n",
        "* Use Cross-Entropy Loss for multi-class classification.\n",
        "* Choose Adam optimizer for faster convergence and adaptive learning rates.\n",
        "\n",
        "Mention the learning rate and other hyperparameters:\n",
        "* Learning rate = 0.001\n",
        "* betas for Adam = (0.9, 0.99)"
      ],
      "metadata": {
        "id": "p6hQ5b5d5LbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = # Code Here\n",
        "optimizer = # Code Here\n"
      ],
      "metadata": {
        "id": "0hHmZ1hD5FBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "qLsNtkW35gup"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step6**: Training the CNN Model\n",
        "\n",
        "We will train the model on the training subset for multiple epochs.\n",
        "\n",
        "**Details:**\n",
        "\n",
        "* Train for **10 epochs**, where each epoch involves multiple iterations over the training subset.\n",
        "\n",
        "Quick Revision:\n",
        "\n",
        "* Forward pass: The model predicts outputs based on input images.\n",
        "* Loss calculation: Compare predictions with true labels using the loss function.\n",
        "* Backward pass: Calculate gradients using backpropagation.\n",
        "* Optimizer step: Update model weights using the optimizer.\n",
        "* Track the loss for each epoch to monitor convergence."
      ],
      "metadata": {
        "id": "xmv0GKWA5hgb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs =\n",
        "train_losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = # Code Here\n",
        "        loss = # Code Here\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss # Code Here\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    train_losses.append(epoch_loss)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n"
      ],
      "metadata": {
        "id": "fUlVqn-i54MQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ei9gJm3_ujpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step7**: Evaluating the Model\n",
        "\n",
        "Now we'll measure the performance of the trained CNN on the test subset.\n",
        "\n",
        "**Details:**\n",
        "* Use the test subset to evaluate accuracy.\n",
        "* Explain the evaluation loop:\n",
        "* Set the model to evaluation mode (disables dropout and other training-only features).\n",
        "* Perform a forward pass for the test images.\n",
        "* Compare predictions with true labels to calculate accuracy.\n"
      ],
      "metadata": {
        "id": "39Ys1rXU6_vm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = # Code Here\n",
        "        _, predicted = # Code Here\n",
        "        total += # Code Here\n",
        "        correct += # Code Here\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"Accuracy on test data: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "id": "7O2rDu7J7UtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "HgEsv2Vl7klV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step8**: Visualizing Predictions\n",
        "\n",
        "**Details:**\n",
        "* Randomly select 25 test images.\n",
        "* Create a 5x5 grid showing the images, their predicted labels, and their true labels.\n",
        "\n"
      ],
      "metadata": {
        "id": "A4RxGCGU7lxf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define class labels for FashionMNIST\n",
        "classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot']\n",
        "\n",
        "# Visualize 9 images with predictions and true labels\n",
        "plt.figure(figsize=(15, 15))\n",
        "for i in range(25):\n",
        "    # Code here\n",
        "    plt.imshow(images[i].cpu().squeeze(), cmap='gray')  # Unnormalize for grayscale\n",
        "    plt.title(f\"Pred: {classes[predicted[i]]}, True: {classes[labels[i]]}\")\n",
        "    plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "fheBm7LT7xSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "lqrShqjN8ATq"
      }
    }
  ]
}